# DrQ-v2 Image-Based RL for SO-101 Lift Task
# Stage 2 sanity check: cube in closed gripper at table level, just needs to lift
# This verifies agent can learn to lift with the new camera view

experiment_name: image_rl

# Environment settings
env:
  env_name: so101_lift
  episode_length: 200
  image_size: 84
  curriculum_stage: 2  # 0=normal, 1=lifted, 2=table grasp, 3=near cube, 4=far
  reward_version: v13  # Use v13 which worked before
  lock_wrist: false
  stddev_schedule: "linear(1.0,0.1,200000)"  # Faster decay for easier task

# Pixel-based training
pixels: true
frame_stack: 3
num_train_envs: 8
batch_size: 256

# Training settings - shorter for sanity check
num_train_frames: 500000
eval_every_steps: 10000
num_eval_episodes: 10
replay_size_before_train: 2000
action_repeat: 2
seed: 1

# Checkpointing
save_snapshot: true
snapshot_every_n: 6250

# Replay buffer
replay:
  size: 100000
  prioritization: false

# DrQ-v2 method overrides
method:
  encoder_model:
    channels: 32
  critic_model:
    mlp_nodes: [256, 256]
  actor_model:
    mlp_nodes: [256, 256]

# Logging
log_eval_video_every_n_evals: 5  # Save video every 5 evals (~400k env steps)

wandb:
  use: false
  entity: gando
  project: so101-image-rl
  name: drqv2_lift_s2_sanity

tb:
  use: true
  log_dir: ./runs/image_rl/tb_logs
  name: drqv2_lift_s2_sanity
